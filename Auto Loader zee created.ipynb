{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1341dac2-5c0e-4e92-979f-010bec6a1273",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c782b82-2ea3-4cd2-9647-9b96d0db441f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.auth.type.zee.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.zee.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.zee.dfs.core.windows.net\", \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2023-08-03T21:41:56Z&st=2023-08-03T13:41:56Z&spr=https&sig=QMrb%2FlACHhwjJ1LNAcIXlqnjIidoinC6CvOaPAkh9JI%3D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b34dc1f9-ae3e-41ab-b4a7-07a66bbbdf6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "driver = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "\n",
    "database_host = \"ankitbhai.database.windows.net\"\n",
    "database_port = \"1433\" # update if you use a non-default port\n",
    "database_name = \"Ankitbhai\"\n",
    "table = \"dbo.employees\"\n",
    "user1 = \"ankitbhai\"\n",
    "password1 = \"Ankit123\"\n",
    "\n",
    "url = f\"jdbc:sqlserver://{database_host}:{database_port};database={database_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725c0f49-0777-4966-bedc-d9fe2feed2dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('jdbc').option('url',url).option(\"dbtable\", table).option(\"user\", user1).option(\"password\", password1).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1902d82f-c3a7-43f3-ad0d-921d501c43ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_id</th><th>first_name</th><th>last_name</th><th>age</th><th>department</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>Doe</td><td>30</td><td>HR</td></tr><tr><td>2</td><td>Jane</td><td>Smith</td><td>28</td><td>IT</td></tr><tr><td>3</td><td>Michael</td><td>Johnson</td><td>35</td><td>Finance</td></tr><tr><td>4</td><td>Emily</td><td>Williams</td><td>25</td><td>Marketing</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         "Doe",
         30,
         "HR"
        ],
        [
         2,
         "Jane",
         "Smith",
         28,
         "IT"
        ],
        [
         3,
         "Michael",
         "Johnson",
         35,
         "Finance"
        ],
        [
         4,
         "Emily",
         "Williams",
         25,
         "Marketing"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"scale\":0}",
         "name": "employee_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"scale\":0}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"scale\":0}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"scale\":0}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"scale\":0}",
         "name": "department",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca771ee9-d941-4f8e-8958-e8485e950b78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark.readStream.format('jdbc').option('url',url).option(\"dbtable\", table).option(\"user\", user1).option(\"password\", password1).load()\n",
    "      .writeStream\n",
    "        .option(\"checkpointLocation\", \"dbfs:/mnt/demo/orders_checkpoint\")\n",
    "        .table(\"orders_updates\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d55a0bb0-3a93-47fe-bd19-baec05c5038b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/ankit/POC/Water_Quality_Testing.csv</td><td>Water_Quality_Testing.csv</td><td>13263</td><td>1686548110000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/ankit/POC/Water_Quality_Testing.csv",
         "Water_Quality_Testing.csv",
         13263,
         1686548110000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path= \"/mnt/ankit/POC/\"\n",
    "\n",
    "\n",
    "files = dbutils.fs.ls(f\"{path}\")\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "128cb8a1-2eda-461e-b34c-942db7c81d84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark.readStream.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(f\"{path}\").writeStream\n",
    "        .option(\"checkpointLocation\", \"dbfs:/mnt/ankit/orders_checkpoint/check1/orders_checkpoint\")\n",
    "        .table(\"dbfs:/mnt/ankit/final/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e993a8-e552-4c9a-88c9-be0926445b2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3445791470341651>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m df2\u001B[38;5;241m=\u001B[39m\u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadStream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mheader\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minferSchema\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdbfs:/mnt/ankit/POC/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/streaming/readwriter.py:275\u001B[0m, in \u001B[0;36mDataStreamReader.load\u001B[0;34m(self, path, format, schema, **options)\u001B[0m\n",
       "\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(path\u001B[38;5;241m.\u001B[39mstrip()) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    272\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf the path is provided for stream, it needs to be a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    273\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-empty string. List of paths are not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    274\u001B[0m         )\n",
       "\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jreader\u001B[38;5;241m.\u001B[39mload())\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m: Schema must be specified when creating a streaming source DataFrame. If some files already exist in the directory, then depending on the file format you may be able to create a static DataFrame on that directory with 'spark.read.load(directory)' and infer schema from it."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)\nFile \u001B[0;32m<command-3445791470341651>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df2\u001B[38;5;241m=\u001B[39m\u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadStream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mheader\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minferSchema\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdbfs:/mnt/ankit/POC/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/streaming/readwriter.py:275\u001B[0m, in \u001B[0;36mDataStreamReader.load\u001B[0;34m(self, path, format, schema, **options)\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(path\u001B[38;5;241m.\u001B[39mstrip()) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    272\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf the path is provided for stream, it needs to be a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    273\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-empty string. List of paths are not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    274\u001B[0m         )\n\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jreader\u001B[38;5;241m.\u001B[39mload())\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mIllegalArgumentException\u001B[0m: Schema must be specified when creating a streaming source DataFrame. If some files already exist in the directory, then depending on the file format you may be able to create a static DataFrame on that directory with 'spark.read.load(directory)' and infer schema from it.",
       "errorSummary": "<span class='ansi-red-fg'>IllegalArgumentException</span>: Schema must be specified when creating a streaming source DataFrame. If some files already exist in the directory, then depending on the file format you may be able to create a static DataFrame on that directory with 'spark.read.load(directory)' and infer schema from it.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2=spark.readStream.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"dbfs:/mnt/ankit/POC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "154994b5-1cd4-483b-8615-8551520d8297",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"PassengerId\", IntegerType(), True),\n",
    "    StructField(\"Survived\", IntegerType(), True),\n",
    "    StructField(\"Pclass\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Sex\", StringType(), True),\n",
    "    StructField(\"Age\", DoubleType(), True),\n",
    "    StructField(\"SibSp\", IntegerType(), True),\n",
    "    StructField(\"Parch\", IntegerType(), True),\n",
    "    StructField(\"Ticket\", StringType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Cabin\", StringType(), True),\n",
    "    StructField(\"Embarked\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e971775-c332-438e-a69e-104304f66c2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen Harris</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr><tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr><tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr><tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. William Henry</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr><tr><td>6</td><td>0</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr><tr><td>7</td><td>0</td><td>1</td><td>McCarthy, Mr. Timothy J</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr><tr><td>8</td><td>0</td><td>3</td><td>Palsson, Master. Gosta Leonard</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr><tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr><tr><td>11</td><td>1</td><td>3</td><td>Sandstrom, Miss. Marguerite Rut</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>PP 9549</td><td>16.7</td><td>G6</td><td>S</td></tr><tr><td>12</td><td>1</td><td>1</td><td>Bonnell, Miss. Elizabeth</td><td>female</td><td>58.0</td><td>0</td><td>0</td><td>113783</td><td>26.55</td><td>C103</td><td>S</td></tr><tr><td>13</td><td>0</td><td>3</td><td>Saundercock, Mr. William Henry</td><td>male</td><td>20.0</td><td>0</td><td>0</td><td>A/5. 2151</td><td>8.05</td><td>null</td><td>S</td></tr><tr><td>14</td><td>0</td><td>3</td><td>Andersson, Mr. Anders Johan</td><td>male</td><td>39.0</td><td>1</td><td>5</td><td>347082</td><td>31.275</td><td>null</td><td>S</td></tr><tr><td>15</td><td>0</td><td>3</td><td>Vestrom, Miss. Hulda Amanda Adolfina</td><td>female</td><td>14.0</td><td>0</td><td>0</td><td>350406</td><td>7.8542</td><td>null</td><td>S</td></tr><tr><td>16</td><td>1</td><td>2</td><td>Hewlett, Mrs. (Mary D Kingcome) </td><td>female</td><td>55.0</td><td>0</td><td>0</td><td>248706</td><td>16.0</td><td>null</td><td>S</td></tr><tr><td>17</td><td>0</td><td>3</td><td>Rice, Master. Eugene</td><td>male</td><td>2.0</td><td>4</td><td>1</td><td>382652</td><td>29.125</td><td>null</td><td>Q</td></tr><tr><td>18</td><td>1</td><td>2</td><td>Williams, Mr. Charles Eugene</td><td>male</td><td>null</td><td>0</td><td>0</td><td>244373</td><td>13.0</td><td>null</td><td>S</td></tr><tr><td>19</td><td>0</td><td>3</td><td>Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)</td><td>female</td><td>31.0</td><td>1</td><td>0</td><td>345763</td><td>18.0</td><td>null</td><td>S</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         0,
         3,
         "Braund, Mr. Owen Harris",
         "male",
         22.0,
         1,
         0,
         "A/5 21171",
         7.25,
         null,
         "S"
        ],
        [
         2,
         1,
         1,
         "Cumings, Mrs. John Bradley (Florence Briggs Thayer)",
         "female",
         38.0,
         1,
         0,
         "PC 17599",
         71.2833,
         "C85",
         "C"
        ],
        [
         3,
         1,
         3,
         "Heikkinen, Miss. Laina",
         "female",
         26.0,
         0,
         0,
         "STON/O2. 3101282",
         7.925,
         null,
         "S"
        ],
        [
         4,
         1,
         1,
         "Futrelle, Mrs. Jacques Heath (Lily May Peel)",
         "female",
         35.0,
         1,
         0,
         "113803",
         53.1,
         "C123",
         "S"
        ],
        [
         5,
         0,
         3,
         "Allen, Mr. William Henry",
         "male",
         35.0,
         0,
         0,
         "373450",
         8.05,
         null,
         "S"
        ],
        [
         6,
         0,
         3,
         "Moran, Mr. James",
         "male",
         null,
         0,
         0,
         "330877",
         8.4583,
         null,
         "Q"
        ],
        [
         7,
         0,
         1,
         "McCarthy, Mr. Timothy J",
         "male",
         54.0,
         0,
         0,
         "17463",
         51.8625,
         "E46",
         "S"
        ],
        [
         8,
         0,
         3,
         "Palsson, Master. Gosta Leonard",
         "male",
         2.0,
         3,
         1,
         "349909",
         21.075,
         null,
         "S"
        ],
        [
         9,
         1,
         3,
         "Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)",
         "female",
         27.0,
         0,
         2,
         "347742",
         11.1333,
         null,
         "S"
        ],
        [
         11,
         1,
         3,
         "Sandstrom, Miss. Marguerite Rut",
         "female",
         4.0,
         1,
         1,
         "PP 9549",
         16.7,
         "G6",
         "S"
        ],
        [
         12,
         1,
         1,
         "Bonnell, Miss. Elizabeth",
         "female",
         58.0,
         0,
         0,
         "113783",
         26.55,
         "C103",
         "S"
        ],
        [
         13,
         0,
         3,
         "Saundercock, Mr. William Henry",
         "male",
         20.0,
         0,
         0,
         "A/5. 2151",
         8.05,
         null,
         "S"
        ],
        [
         14,
         0,
         3,
         "Andersson, Mr. Anders Johan",
         "male",
         39.0,
         1,
         5,
         "347082",
         31.275,
         null,
         "S"
        ],
        [
         15,
         0,
         3,
         "Vestrom, Miss. Hulda Amanda Adolfina",
         "female",
         14.0,
         0,
         0,
         "350406",
         7.8542,
         null,
         "S"
        ],
        [
         16,
         1,
         2,
         "Hewlett, Mrs. (Mary D Kingcome) ",
         "female",
         55.0,
         0,
         0,
         "248706",
         16.0,
         null,
         "S"
        ],
        [
         17,
         0,
         3,
         "Rice, Master. Eugene",
         "male",
         2.0,
         4,
         1,
         "382652",
         29.125,
         null,
         "Q"
        ],
        [
         18,
         1,
         2,
         "Williams, Mr. Charles Eugene",
         "male",
         null,
         0,
         0,
         "244373",
         13.0,
         null,
         "S"
        ],
        [
         19,
         0,
         3,
         "Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)",
         "female",
         31.0,
         1,
         0,
         "345763",
         18.0,
         null,
         "S"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PassengerId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Survived",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Pclass",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sex",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "SibSp",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Parch",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Ticket",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Fare",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Cabin",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Embarked",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.readStream.format(\"csv\").schema(schema).option(\"header\", True).load(\"abfs://csv@zee.dfs.core.windows.net/Gold/\")\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e5226db-9fda-43f0-869d-702082239fd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[69]: <pyspark.sql.streaming.query.StreamingQuery at 0x7f01f9125130>"
     ]
    }
   ],
   "source": [
    "df.writeStream.format(\"parquet\").outputMode(\"append\").option(\"path\", \"abfs://csv@zee.dfs.core.windows.net/final/\").option(\"checkpointLocation\", \"abfs://csv@zee.dfs.core.windows.net/orders_checkpoint/\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "630ab080-5890-47d5-8edf-11cf81391ff8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32c3c902-3576-4c01-8452-d2eb4ee1a814",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89c207a3-8f3e-4a05-81d6-a865b4649fdb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc8fa659-2618-455c-b44b-da61982198fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e6f4ecb-a45d-4808-b7b2-e8e808f3f33b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c92765d8-ecec-48ad-9f52-d9d8bff16511",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3fceade-a3cd-4779-9b96-f0436df9eed5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07178e52-7b67-4e09-a8f6-61104041ef81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2023-08-03 16:44:07",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
